{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import scipy.stats as ss\n",
    "#from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from itertools import product\n",
    "#import matplotlib.pyplot as plt\n",
    "#from imblearn.over_sampling import SMOTENC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rf_tuning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rf_tuning.py\n",
    "\n",
    "import numpy as np\n",
    "from numpy import pi, exp, sqrt\n",
    "from mpi4py import MPI\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "#from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "X = pd.read_csv('input.csv')\n",
    "y = X['target']\n",
    "X = X.drop(columns = ['target'])\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "n_estimators = [50,100]\n",
    "max_features = ['sqrt','log2']\n",
    "max_depth = [5,10]\n",
    "min_samples_split = [10,20]\n",
    "param_grid_prod = list(product(n_estimators,max_features,max_depth,min_samples_split))\n",
    "num_params = len(param_grid_prod)\n",
    "\n",
    "def rf_model (X_train,y_train,X_test,y_test,param):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    parm = [max_depth, n_estimators, 'min_samples_split', 'max_features']\n",
    "    \n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators = param[0],max_features = param[1],max_depth = param[2], min_samples_split = param[3])\n",
    "    #rf.grid = GridSearchCV(rf, param_grid,cv = 5,scoring = 'roc_auc')\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_test_prob = rf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_test_prob)\n",
    "    #print(param, auc)\n",
    "    return auc\n",
    "\n",
    "#n = np.array(num_params)\n",
    "auc = np.zeros(1)\n",
    "auc_list = np.zeros(num_params)\n",
    "param_idx = np.zeros(num_params)\n",
    "auc_rank = np.zeros(size)\n",
    "param_list = []\n",
    "\n",
    "# Compute partition\n",
    "for i in range(num_params):\n",
    "    if rank == i%size:\n",
    "        auc = rf_model (X_train, y_train, X_test, y_test,param_grid_prod[i])\n",
    "        #param_list.append(param_grid_prod[i])\n",
    "        auc_list[i] = auc\n",
    "        param_idx[i] = i\n",
    "\n",
    "for i in range(size):\n",
    "    if rank == i:\n",
    "        print('Rank: ', rank)\n",
    "        print('max_auc of current rank: ', np.max(auc_list))\n",
    "        #auc_rank[i] = np.max(auc_list)\n",
    "        #print('whole auc_rank: ',auc_rank)\n",
    "        max_idx = np.argmax(auc_list)\n",
    "        print('best parameter combincation: ',param_grid_prod[max_idx])\n",
    "        #param_list.append(param_grid_prod[max_idx])\n",
    "        \n",
    "end = time.time()\n",
    "print('Time elapsed: ', end - start)\n",
    "        \n",
    "\"\"\"        \n",
    "print('auc:',auc_rank)\n",
    "print('param:',param_list)\n",
    "\n",
    "if rank == 0:\n",
    "    print('Rank: ',rank)\n",
    "    print(max(auc_list))\n",
    "    print(np.argmax(auc_list))\n",
    "\n",
    "if rank == 1:\n",
    "    print('Rank: ', rank)\n",
    "    print(max(auc_list))\n",
    "    print(np.argmax(auc_list))\n",
    "\n",
    "\n",
    "max_idx = np.argmax(auc_list)\n",
    "print('max_idx:',max_idx)\n",
    "print('param:',param_grid_prod[max_idx])\n",
    "print('best_auc:',auc_list[max_idx])\n",
    "print('param_list:', len(param_list))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mpirun -n 4 python3 rf_tuning.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rf_tuning.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile rf_tuning.py\n",
    "\n",
    "import numpy as np\n",
    "from numpy import pi, exp, sqrt\n",
    "from mpi4py import MPI\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "#from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "X = pd.read_csv('input.csv')\n",
    "y = X['target']\n",
    "X = X.drop(columns = ['target'])\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "n_estimators = [50,100]\n",
    "max_features = ['sqrt','log2']\n",
    "max_depth = [5,10]\n",
    "min_samples_split = [10,20]\n",
    "param_grid_prod = list(product(n_estimators,max_features,max_depth,min_samples_split))\n",
    "num_params = len(param_grid_prod)\n",
    "rank_size = num_params // size\n",
    "\n",
    "def rf_model (X_train,y_train,X_test,y_test,param):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    parm = [max_depth, n_estimators, 'min_samples_split', 'max_features']\n",
    "    \n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators = param[0],max_features = param[1],max_depth = param[2], min_samples_split = param[3])\n",
    "    #rf.grid = GridSearchCV(rf, param_grid,cv = 5,scoring = 'roc_auc')\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_test_prob = rf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_test_prob)\n",
    "    print(param, auc)\n",
    "    return auc\n",
    "\n",
    "#n = np.array(num_params)\n",
    "auc = np.zeros(1)\n",
    "#auc_list = np.zeros(num_params)\n",
    "#param_idx = np.zeros(num_params)\n",
    "auc_rank = np.zeros(size)\n",
    "#param_rank = []\n",
    "#param_list = []\n",
    "best_auc = np.zeros(1)\n",
    "param_rank = np.empty(4, dtype = 'object')\n",
    "param_result = np.empty(4, dtype = 'object')\n",
    "\n",
    "\n",
    "if rank == (size-1):\n",
    "    sub_param_grid = param_grid_prod[rank*rank_size:num_params]\n",
    "    auc_result = []\n",
    "    #auc_result = np.zeros(N - rank*rank_size)\n",
    "    for param in sub_param_grid:\n",
    "        auc = rf_model(X_train, y_train, X_test, y_test,param)\n",
    "        auc_result.append(auc)\n",
    "    best_auc = np.max(auc_result)\n",
    "    idx = np.argmax(best_auc)\n",
    "    best_param = sub_param_grid[idx]\n",
    "    #comm.Gather(best_auc, auc_rank, root=0)\n",
    "    print('Rank: ',rank, 'Best AUC: ', best_auc, 'Best Parameter: ',best_param)\n",
    "\n",
    "else:\n",
    "    sub_param_grid = param_grid_prod[rank*rank_size:(rank+1)*rank_size]\n",
    "    auc_result = []\n",
    "    param_list = []\n",
    "    for i in range(len(sub_param_grid)):\n",
    "        auc = rf_model(X_train, y_train, X_test, y_test,sub_param_grid[i])\n",
    "        auc_result.append(auc)\n",
    "    \n",
    "    best_auc = np.max(auc_result)\n",
    "    idx = np.argmax(best_auc)\n",
    "    best_param = sub_param_grid[idx]\n",
    "    print('Rank: ',rank, 'Best AUC: ', best_auc, 'Best Parameter: ',best_param)\n",
    "\n",
    "\n",
    "#param_rank.append(best_param)\n",
    "        \n",
    "#comm.Gather(best_auc, auc_rank, root=0)\n",
    "#comm.Gather(param_result,param_rank, root=0)\n",
    "\n",
    "\n",
    "# Only print the result in process 0\n",
    "#if rank == 0:\n",
    "#    print('final_result: ',auc_rank)\n",
    "#    print('best_parameter: ',param_result)\n",
    "    #print(best_param)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting rf_tuning.py\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%writefile rf_tuning.py\n",
    "\n",
    "import numpy as np\n",
    "from numpy import pi, exp, sqrt\n",
    "from mpi4py import MPI\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from itertools import product\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "#from imblearn.over_sampling import SMOTENC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "size = comm.Get_size()\n",
    "\n",
    "X = pd.read_csv('input.csv')\n",
    "y = X['target']\n",
    "X = X.drop(columns = ['target'])\n",
    "X = X.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "\n",
    "n_estimators = [50,100]\n",
    "max_features = ['sqrt','log2']\n",
    "max_depth = [5,10]\n",
    "min_samples_split = [10,20]\n",
    "param_grid_prod = list(product(n_estimators,max_features,max_depth,min_samples_split))\n",
    "num_params = len(param_grid_prod)\n",
    "rank_size = num_params // size\n",
    "\n",
    "def rf_model (X_train,y_train,X_test,y_test,param):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "    parm = [max_depth, n_estimators, 'min_samples_split', 'max_features']\n",
    "    \n",
    "    \"\"\"\n",
    "    rf = RandomForestClassifier(n_estimators = param[0],max_features = param[1],max_depth = param[2], min_samples_split = param[3])\n",
    "    #rf.grid = GridSearchCV(rf, param_grid,cv = 5,scoring = 'roc_auc')\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_test_prob = rf.predict_proba(X_test)[:,1]\n",
    "    auc = roc_auc_score(y_test, y_test_prob)\n",
    "    print(param, auc)\n",
    "    return auc\n",
    "\n",
    "#n = np.array(num_params)\n",
    "auc = np.zeros(1)\n",
    "#auc_list = np.zeros(num_params)\n",
    "#param_idx = np.zeros(num_params)\n",
    "auc_rank = np.zeros(size)\n",
    "#param_rank = []\n",
    "#param_list = []\n",
    "best_auc = np.zeros(1)\n",
    "#param_rank = np.empty(4, dtype = 'object')\n",
    "#param_result = np.empty(4, dtype = 'object')\n",
    "#best_param = np.empty(4, dtype = 'object')\n",
    "\n",
    "\n",
    "if rank == (size-1):\n",
    "    sub_param_grid = param_grid_prod[rank*rank_size:num_params]\n",
    "    auc_result = []\n",
    "    #auc_result = np.zeros(N - rank*rank_size)\n",
    "    for param in sub_param_grid:\n",
    "        auc = rf_model(X_train, y_train, X_test, y_test,param)\n",
    "        auc_result.append(auc)\n",
    "    best_auc = np.max(auc_result)\n",
    "    #comm.Gather(best_auc, auc_rank, root=0)\n",
    "\n",
    "else:\n",
    "\n",
    "sub_param_grid = param_grid_prod[rank*rank_size:(rank+1)*rank_size]\n",
    "auc_result = []\n",
    "param_list = []\n",
    "for i in range(len(sub_param_grid)):\n",
    "    auc = rf_model(X_train, y_train, X_test, y_test,sub_param_grid[i])\n",
    "    auc_result.append(auc)\n",
    "    \n",
    "best_auc = np.max(auc_result)\n",
    "idx = np.argmax(best_auc)\n",
    "best_param = sub_param_grid[idx]\n",
    "param_result = (rank, best_param)\n",
    "#print('Rank: ',rank, 'Best AUC: ', best_auc, 'Best Parameter: ',best_param)\n",
    "\n",
    "\n",
    "#param_rank.append(best_param)\n",
    "        \n",
    "#comm.Gather(best_auc, auc_rank, root=0)\n",
    "comm.gather(param_result, root=0)\n",
    "\n",
    "\n",
    "# Only print the result in process 0\n",
    "if rank == 0:\n",
    "    for i in range(size):\n",
    "        print(param_result[i])\n",
    "#    print('final_result: ',auc_rank)\n",
    "    #print('best_parameter: ',param_result)\n",
    "    #print(best_param)\n",
    "\"\"\"\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
